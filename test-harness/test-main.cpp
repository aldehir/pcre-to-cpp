// Test harness for PCRE to C++ converter
// Reads JSON input from stdin, runs tokenization, outputs JSON results

#include <iostream>
#include <string>
#include <vector>
#include <sstream>

#include "unicode.h"

// Forward declaration - this function is generated by pcre_to_cpp.py --name test
std::vector<size_t> unicode_regex_split_test(
    const std::string & text,
    const std::vector<size_t> & offsets
);

// Simple JSON string escaping
std::string json_escape(const std::string & s) {
    std::string result;
    result.reserve(s.size() + 16);
    for (unsigned char c : s) {
        switch (c) {
            case '"':  result += "\\\""; break;
            case '\\': result += "\\\\"; break;
            case '\b': result += "\\b"; break;
            case '\f': result += "\\f"; break;
            case '\n': result += "\\n"; break;
            case '\r': result += "\\r"; break;
            case '\t': result += "\\t"; break;
            default:
                if (c < 0x20) {
                    char buf[8];
                    snprintf(buf, sizeof(buf), "\\u%04x", c);
                    result += buf;
                } else {
                    result += c;
                }
        }
    }
    return result;
}

// Parse a JSON string value (expects input starting after opening quote)
std::string parse_json_string(const std::string & json, size_t & pos) {
    std::string result;
    while (pos < json.size()) {
        char c = json[pos++];
        if (c == '"') {
            return result;
        } else if (c == '\\' && pos < json.size()) {
            char next = json[pos++];
            switch (next) {
                case '"':  result += '"'; break;
                case '\\': result += '\\'; break;
                case '/':  result += '/'; break;
                case 'b':  result += '\b'; break;
                case 'f':  result += '\f'; break;
                case 'n':  result += '\n'; break;
                case 'r':  result += '\r'; break;
                case 't':  result += '\t'; break;
                case 'u':  // Unicode escape
                    if (pos + 4 <= json.size()) {
                        // Parse the 4 hex digits
                        int codepoint = 0;
                        for (int i = 0; i < 4; i++) {
                            char hex = json[pos++];
                            codepoint *= 16;
                            if (hex >= '0' && hex <= '9') codepoint += hex - '0';
                            else if (hex >= 'a' && hex <= 'f') codepoint += hex - 'a' + 10;
                            else if (hex >= 'A' && hex <= 'F') codepoint += hex - 'A' + 10;
                        }

                        // Check if it's a high surrogate (0xD800-0xDBFF)
                        if (codepoint >= 0xD800 && codepoint <= 0xDBFF) {
                            // Look for low surrogate: \uXXXX pattern
                            if (pos + 6 <= json.size() && json[pos] == '\\' && json[pos+1] == 'u') {
                                // Parse the low surrogate
                                int low = 0;
                                size_t temp_pos = pos + 2;
                                for (int i = 0; i < 4; i++) {
                                    char hex = json[temp_pos++];
                                    low *= 16;
                                    if (hex >= '0' && hex <= '9') low += hex - '0';
                                    else if (hex >= 'a' && hex <= 'f') low += hex - 'a' + 10;
                                    else if (hex >= 'A' && hex <= 'F') low += hex - 'A' + 10;
                                }

                                if (low >= 0xDC00 && low <= 0xDFFF) {
                                    // Valid surrogate pair - combine them
                                    codepoint = 0x10000 + ((codepoint & 0x3FF) << 10) + (low & 0x3FF);
                                    pos += 6;  // Skip the \uXXXX we just consumed
                                } else {
                                    // Invalid pair - use replacement character
                                    codepoint = 0xFFFD;
                                }
                            } else {
                                // Lone high surrogate - use replacement character
                                codepoint = 0xFFFD;
                            }
                        } else if (codepoint >= 0xDC00 && codepoint <= 0xDFFF) {
                            // Lone low surrogate - use replacement character
                            codepoint = 0xFFFD;
                        }

                        result += unicode_cpt_to_utf8(codepoint);
                    }
                    break;
                default: result += next; break;
            }
        } else {
            result += c;
        }
    }
    return result;
}

// Parse JSON input: {"strings": ["test1", "test2", ...]}
std::vector<std::string> parse_input(const std::string & json) {
    std::vector<std::string> result;

    // Find "strings" key
    size_t pos = json.find("\"strings\"");
    if (pos == std::string::npos) return result;

    // Find the array start
    pos = json.find('[', pos);
    if (pos == std::string::npos) return result;
    pos++; // skip '['

    // Parse strings until ']'
    while (pos < json.size()) {
        // Skip whitespace
        while (pos < json.size() && (json[pos] == ' ' || json[pos] == '\t' ||
               json[pos] == '\n' || json[pos] == '\r' || json[pos] == ',')) {
            pos++;
        }

        if (pos >= json.size() || json[pos] == ']') break;

        if (json[pos] == '"') {
            pos++; // skip opening quote
            result.push_back(parse_json_string(json, pos));
        } else {
            pos++;
        }
    }

    return result;
}

// Convert offset list to token strings
std::vector<std::string> offsets_to_tokens(const std::string & text, const std::vector<size_t> & offsets) {
    std::vector<std::string> tokens;
    auto cpts = unicode_cpts_from_utf8(text);

    size_t pos = 0;
    for (size_t offset : offsets) {
        std::string token;
        for (size_t i = 0; i < offset && pos + i < cpts.size(); i++) {
            token += unicode_cpt_to_utf8(cpts[pos + i]);
        }
        tokens.push_back(token);
        pos += offset;
    }

    return tokens;
}

int main() {
    // Read all input from stdin
    std::stringstream buffer;
    buffer << std::cin.rdbuf();
    std::string input = buffer.str();

    // Parse input
    std::vector<std::string> test_strings = parse_input(input);

    // Process each string
    std::cout << "{\"results\": [";

    for (size_t i = 0; i < test_strings.size(); i++) {
        const std::string & text = test_strings[i];

        // Get initial offsets (single chunk = entire text in codepoints)
        auto cpts = unicode_cpts_from_utf8(text);
        std::vector<size_t> initial_offsets = { cpts.size() };

        // Run the generated regex split
        auto result_offsets = unicode_regex_split_test(text, initial_offsets);

        // Convert to tokens
        auto tokens = offsets_to_tokens(text, result_offsets);

        // Output JSON array
        if (i > 0) std::cout << ", ";
        std::cout << "[";
        for (size_t j = 0; j < tokens.size(); j++) {
            if (j > 0) std::cout << ", ";
            std::cout << "\"" << json_escape(tokens[j]) << "\"";
        }
        std::cout << "]";
    }

    std::cout << "]}" << std::endl;

    return 0;
}
